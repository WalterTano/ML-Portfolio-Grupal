{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/ut2-pd2/","result":{"data":{"datoCmsBlogpost":{"id":"DatoCmsBlogpost-184048124","slug":"ut2-pd2","title":"Otros Tutoriales de RapidMiner","excerpt":"Realizamos y describimos algunos tutoriales de RapidMiner.","date":null,"html":"- **Modeling**\n\nUtilizando bloques para algunos algoritmos de aprendizaje automático supervisados (Decision Tree, Naive Bayes y Rule Induction), se generaron modelos predictivos para la supervivencia de los pasajeros del Titanic.\nSe encontró que las mujeres, en general, tenían una probabilidad de supervivencia mayor que los hombres, pero que este último grupo no tenía ningún sesgo aparente por el tamaño familiar, mientras que el primero sí. Esta información se vuelve evidente al observar los resultados de los modelos que provee RapidMiner. El sesgo basado en género se vuelve especialmente visible al visualizar el resultado del modelo que utiliza Naive Bayes en una gráfica de barras\n\n  ![Untitled](https://www.datocms-assets.com/106983/1696362474-ut2-pd2-1.png)\n    \n- **Scoring**\n\nNuevamente, utilizando el dataset de Titanic y el algoritmo Naive Bayes, se agregó el bloque *Apply Model* para probar el modelo entrenado con un subconjunto de datos de Titanic, esta vez sin un valor en la variable objetivo (*survived*, si el pasajero sobrevivió).\nAl inspeccionar el resultado, podemos encontrar predicciones hechas sobre los datos de prueba provistos. Además, se incluye un nivel de confianza que va desde 0 a 1 e indica la probabilidad de certeza (según el entrenamiento del modelo) en la predicción realizada. Podemos observar que si la confianza por una determinada opción (en este caso “Sí” o “No”) supera el 50% (o 0.5), el modelo decanta su predicción hacia esa alternativa, ya que la identifica como la más probable.\nAl cambiar el algoritmo utilizado por Decision Tree, podemos observar cambios en los valores de confianza agregados al resultado. En Naive Bayes, estos valores son continuos e incluyen una alta variedad de valores dentro del rango. Por otro lado, los valores de confianza generados por un Decision Tree son más bien discretos, formándose agrupaciones de varios registros en un mismo porcentaje. Esto se debe a que, mientras Decision Tree define un árbol de alternativas, haciendo que las predicciones se basen en caminos definidos, Naive Bayes es un algoritmo probabilístico que no se ve limitado tan estrictamente.\n\n![Gráficos de barras de las distribuciones de las probabilidades de confianza. En la izquierda, utilizando el algoritmo Naive Bayes. En la derecha, utilizando Decision Tree.](https://www.datocms-assets.com/106983/1696362480-ut2-pd2-2.png)\n\nGráficos de barras de las distribuciones de las probabilidades de confianza. En la izquierda, utilizando el algoritmo Naive Bayes. En la derecha, utilizando Decision Tree.\n\n- ***Test Splits and Validation***: En este tutorial, utilizamos el bloque *Split Data* para dividir nuestro conjunto de datos inicial en dos subconjuntos. De esta forma, optimizamos el uso de los datos (que son por naturaleza limitados y costosos de obtener) para generar y testear nuestros modelos.\nEn este caso, realizamos una partición de los datos en 70/30, donde el 70% de los datos es utilizado para entrenar el modelo y el 30% para probarlo.\nSe incluyó un bloque *Performance* para evaluar el rendimiento del modelo entrenado y se encontró que tuvo una precisión del 80.36%. Junto al resultado se incluye una matriz de confusión, donde podemos ver la cantidad de veces que se realizaron predicciones erróneas para las clases definidas y el porcentaje de predicciones correctas para cada una.\n    \n    ![Untitled](https://www.datocms-assets.com/106983/1696362484-ut2-pd2-3.png)\n    \n- ***Cross Validation***: En este tutorial, se utiliza el bloque *Cross Validation*, que es el operador que nos ayudará a realizar una validación cruzada. Por defecto, divide los datos en 10 partes, pero esto es customizable en los parámetros del bloque. Al hacer doble click en el bloque, podemos ver que contiene 2 subprocesos, uno para entrenar un modelo y otro para testearlo. Aprovechando este bloque, podemos generar un proceso (simple o complejo) para el entrenamiento y testeo de nuestro modelo y realizar una validación cruzada con todos los subconjuntos de nuestro conjunto de datos que creamos necesario, obteniendo como salida el promedio del resultado de las evaluaciones de rendimiento.\nAl inspeccionar los resultados de esta evaluación de rendimiento, además de tener un porcentaje de precisión del 80.35% y una matriz de confusión, también tenemos la desviación estándar del porcentaje de precisión a través de todas las instancias de testeo, que es ±4.69%. Mientras menor sea esta desviación, menor es la dependencia del rendimiento del modelo en el conjunto de datos de prueba.\n    \n    ![Untitled](https://www.datocms-assets.com/106983/1696362489-ut2-pd2-4.png)\n    \n- ***Visual Model Comparison***: En este tutorial, utilizamos el bloque *Compare ROCs*, que permite comparar las curvas ROC (representaciones gráficas que ilustran información sobre la frecuencia de falsos positivos en sistemas de clasificación binarios) de diversos modelos, para evaluar y comparar sus rendimientos. \nPara esta comparación, se utilizan los modelos Decision Tree, Naive Bayes y Rule Induction. En las curvas ROC resultantes, podemos observar que, en general, los 3 modelos utilizados son mejores para predecir que la selección aleatoria. Sin embargo, el modelo generado con Naive Bayes es un claro perdedor en términos de rendimiento al compararlo con los otros 2.\n    \n    ![Untitled](https://www.datocms-assets.com/106983/1696362493-ut2-pd2-5.png)","isMarkdown":true,"image":{"url":"https://www.datocms-assets.com/106983/1696362493-ut2-pd2-5.png?auto=format","gatsbyImageData":{"images":{"sources":[],"fallback":{"src":"https://www.datocms-assets.com/106983/1696362493-ut2-pd2-5.png?auto=format&w=993","srcSet":"https://www.datocms-assets.com/106983/1696362493-ut2-pd2-5.png?auto=format&dpr=0.25&w=993 248w,\nhttps://www.datocms-assets.com/106983/1696362493-ut2-pd2-5.png?auto=format&dpr=0.51&w=993 497w,\nhttps://www.datocms-assets.com/106983/1696362493-ut2-pd2-5.png?auto=format&w=993 993w","sizes":"(min-width: 993px) 993px, 100vw"}},"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAASCAIAAADDkPmOAAAAAXNSR0IArs4c6QAAAgxJREFUOE+tVctu3DAMnKEe9nqd7KZIAxT9/y8rCvRStM2+bNni9OBNGqRBkqaZi0CBHFHikGKZ5nkqFgyQHNFsrlVEkxujSSIIAsTrIQlAdK9ePcYoiQYRFgJhECoFA+GuShekJUySXC4JvOMBAAESSOaYzRgJhRhSSpJILOlNZb8//iooIKZp0qSotsrcBQggGBAizQgIMGMwAgQthdBmLlnL3SGRHFVqOdTh+P3wdRxH92ZSDlo1zWVOHc1ygyYGCxZCsGBGEiBB0ggAJElIcve42CKH8fbkh+Pu27Dfn0pIfpMuby7W6z6lpmUwBCI89+IClvc625GkANV5/+NL8f3xOA21i9h2q22/6TcXKcABnQP9LpI8r38fQS6bcTG1383Hn6eAnD8bNt26+dDnFC3IJeiegXdxr5BMlGSwY93dBnjzkXbdpe76kjmYJF9q9hLLk4gkZ00nDnV106ZPmOOqUTa6O/5c7i0wworGMg1eU/C2S9alpUP4P7wADAClwzgF9U1kk5mjCe8AI1BRT0yr2LcZmzZg6Yr/yhgAjMbd4TCfbN3aOpuR0hvr9ghGow8WynTVWzL6ud3fAVES3bdXfbAo95f8H+PcQnxCotFdfRMvt9cE/N/V9ow/T8OgUtrVys2gd5EGAEhirXUcCwhK97KQRPL8D0BaRpgEgOAyUPjA+SHpsk/yN0SRHuX97dScAAAAAElFTkSuQmCC"},"width":993,"height":591},"alt":null}}},"pageContext":{"id":"DatoCmsBlogpost-184048124"}},"staticQueryHashes":["1987388502","3342712670"],"slicesMap":{"footer":"footer","header":"header"}}